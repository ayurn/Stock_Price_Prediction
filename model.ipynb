{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@Author: Ayur Ninawe\n",
    "@Date: 06-09-2021\n",
    "@Last Modified by: Ayur Ninawe\n",
    "@Last Modified time: 06-09-2021\n",
    "@Title : Program to clean data and to create ML model for stock price prediction.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-03 16:42:00</td>\n",
       "      <td>2874.50</td>\n",
       "      <td>2874.50</td>\n",
       "      <td>2874.50</td>\n",
       "      <td>2874.50</td>\n",
       "      <td>286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-03 16:31:00</td>\n",
       "      <td>2875.00</td>\n",
       "      <td>2875.00</td>\n",
       "      <td>2875.00</td>\n",
       "      <td>2875.00</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-03 16:28:00</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>613.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-03 16:15:00</td>\n",
       "      <td>2875.00</td>\n",
       "      <td>2875.00</td>\n",
       "      <td>2874.50</td>\n",
       "      <td>2874.50</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-03 16:11:00</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  1. open  2. high   3. low  4. close  5. volume\n",
       "0  2021-09-03 16:42:00  2874.50  2874.50  2874.50   2874.50      286.0\n",
       "1  2021-09-03 16:31:00  2875.00  2875.00  2875.00   2875.00      103.0\n",
       "2  2021-09-03 16:28:00  2874.79  2874.79  2874.79   2874.79      613.0\n",
       "3  2021-09-03 16:15:00  2875.00  2875.00  2874.50   2874.50      279.0\n",
       "4  2021-09-03 16:11:00  2874.79  2874.79  2874.79   2874.79      203.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Getting data from S3 bucket and saving it to dataframe.'''\n",
    "\n",
    "path ='s3://ayurnaws/google_stock_data.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date      0\n",
       "Open      0\n",
       "High      0\n",
       "Low       0\n",
       "Close     0\n",
       "Volume    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Using Pandas to read data from S3 and return clean dataframe\n",
    "'''\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "        # Renaming columns\n",
    "df = df.rename(columns={df.columns[1]: 'Open'})\n",
    "df = df.rename(columns={df.columns[3]: 'Low'})\n",
    "df = df.rename(columns={df.columns[4]: 'Close'})\n",
    "df = df.rename(columns={df.columns[5]: 'Volume'})\n",
    "df = df.rename(columns={df.columns[2]: 'High'})\n",
    "\n",
    "df.dtypes\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''convert string Date into Datetime format '''\n",
    "\n",
    "# df['date'] = pd.to_datetime(df.date)\n",
    "# df['date'] = df [\"date\"].dt.strftime('%m/%d/%y')\n",
    "# df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-03 16:42:00</td>\n",
       "      <td>2874.50</td>\n",
       "      <td>2874.50</td>\n",
       "      <td>2874.50</td>\n",
       "      <td>2874.50</td>\n",
       "      <td>286.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-03 16:31:00</td>\n",
       "      <td>2875.00</td>\n",
       "      <td>2875.00</td>\n",
       "      <td>2875.00</td>\n",
       "      <td>2875.00</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-03 16:28:00</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>613.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-03 16:15:00</td>\n",
       "      <td>2875.00</td>\n",
       "      <td>2875.00</td>\n",
       "      <td>2874.50</td>\n",
       "      <td>2874.50</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-03 16:11:00</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>2874.79</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date     Open     High      Low    Close  Volume\n",
       "0  2021-09-03 16:42:00  2874.50  2874.50  2874.50  2874.50   286.0\n",
       "1  2021-09-03 16:31:00  2875.00  2875.00  2875.00  2875.00   103.0\n",
       "2  2021-09-03 16:28:00  2874.79  2874.79  2874.79  2874.79   613.0\n",
       "3  2021-09-03 16:15:00  2875.00  2875.00  2874.50  2874.50   279.0\n",
       "4  2021-09-03 16:11:00  2874.79  2874.79  2874.79  2874.79   203.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Here we start Data Modeling by pyspark our clean data available on 'df'''\n",
    "\n",
    "'''First import all important libraries of pyspark for modeling process'''\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "'''Convert pandas Dataframe to pyspark Dataframe'''\n",
    "# sc = SparkContext()\n",
    "# sparkSession = SparkSession(sc)\n",
    "stock_price_data = sparkSession.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: double (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stock_price_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>3743</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-08-23 04:16:00</td>\n",
       "      <td>2021-09-03 16:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>3743</td>\n",
       "      <td>2864.4487212396475</td>\n",
       "      <td>35.45578737179685</td>\n",
       "      <td>2753.14</td>\n",
       "      <td>2924.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>High</th>\n",
       "      <td>3743</td>\n",
       "      <td>2864.952777958855</td>\n",
       "      <td>35.41839308107878</td>\n",
       "      <td>2754.7499</td>\n",
       "      <td>2925.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Low</th>\n",
       "      <td>3743</td>\n",
       "      <td>2863.9210248730965</td>\n",
       "      <td>35.490252196114234</td>\n",
       "      <td>2752.15</td>\n",
       "      <td>2924.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close</th>\n",
       "      <td>3743</td>\n",
       "      <td>2864.440174565856</td>\n",
       "      <td>35.44219184633815</td>\n",
       "      <td>2752.15</td>\n",
       "      <td>2925.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume</th>\n",
       "      <td>3743</td>\n",
       "      <td>2751.7493988779056</td>\n",
       "      <td>4020.0574534657085</td>\n",
       "      <td>100.0</td>\n",
       "      <td>127004.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                   1                   2                    3  \\\n",
       "summary  count                mean              stddev                  min   \n",
       "date      3743                None                None  2021-08-23 04:16:00   \n",
       "Open      3743  2864.4487212396475   35.45578737179685              2753.14   \n",
       "High      3743   2864.952777958855   35.41839308107878            2754.7499   \n",
       "Low       3743  2863.9210248730965  35.490252196114234              2752.15   \n",
       "Close     3743   2864.440174565856   35.44219184633815              2752.15   \n",
       "Volume    3743  2751.7493988779056  4020.0574534657085                100.0   \n",
       "\n",
       "                           4  \n",
       "summary                  max  \n",
       "date     2021-09-03 16:42:00  \n",
       "Open                 2924.93  \n",
       "High                2925.075  \n",
       "Low                  2924.48  \n",
       "Close               2925.075  \n",
       "Volume              127004.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_price_data.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing linear regression from pyspark mllib\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Stock processing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import percent_rank\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+-------+---------+--------+-------+--------------------+\n",
      "|               date|    Open|   High|      Low|   Close| Volume|Independent_Features|\n",
      "+-------------------+--------+-------+---------+--------+-------+--------------------+\n",
      "|2021-09-03 16:42:00|  2874.5| 2874.5|   2874.5|  2874.5|  286.0|[2874.5,2874.5,28...|\n",
      "|2021-09-03 16:31:00|  2875.0| 2875.0|   2875.0|  2875.0|  103.0|[2875.0,2875.0,28...|\n",
      "|2021-09-03 16:28:00| 2874.79|2874.79|  2874.79| 2874.79|  613.0|[2874.79,2874.79,...|\n",
      "|2021-09-03 16:15:00|  2875.0| 2875.0|   2874.5|  2874.5|  279.0|[2875.0,2875.0,28...|\n",
      "|2021-09-03 16:11:00| 2874.79|2874.79|  2874.79| 2874.79|  203.0|[2874.79,2874.79,...|\n",
      "|2021-09-03 16:10:00|  2874.5| 2874.5|   2874.5|  2874.5|  121.0|[2874.5,2874.5,28...|\n",
      "|2021-09-03 16:05:00|  2875.0| 2875.0|   2875.0|  2875.0|  135.0|[2875.0,2875.0,28...|\n",
      "|2021-09-03 16:03:00| 2874.79|2874.79|  2874.79| 2874.79| 1471.0|[2874.79,2874.79,...|\n",
      "|2021-09-03 16:01:00| 2874.79|2874.79|  2874.79| 2874.79| 4570.0|[2874.79,2874.79,...|\n",
      "|2021-09-03 16:00:00| 2872.24|2875.16|   2871.8|  2874.8|19612.0|[2872.24,2875.16,...|\n",
      "|2021-09-03 15:59:00|2870.745|2872.57|2870.5828|2872.365| 8819.0|[2870.745,2872.57...|\n",
      "|2021-09-03 15:58:00| 2869.33|2870.83|   2869.1| 2870.77|13476.0|[2869.33,2870.83,...|\n",
      "|2021-09-03 15:57:00| 2868.44|2870.08|  2868.28| 2868.28| 9766.0|[2868.44,2870.08,...|\n",
      "|2021-09-03 15:56:00| 2869.67|2869.71|   2868.0| 2868.34|18844.0|[2869.67,2869.71,...|\n",
      "|2021-09-03 15:55:00| 2871.14|2871.62|  2869.89| 2869.89| 8401.0|[2871.14,2871.62,...|\n",
      "|2021-09-03 15:54:00|  2871.2|2872.17|   2871.2| 2871.28|11151.0|[2871.2,2872.17,2...|\n",
      "|2021-09-03 15:53:00|2871.625|2872.22|  2870.67| 2870.67| 8554.0|[2871.625,2872.22...|\n",
      "|2021-09-03 15:52:00| 2872.71|2872.75|   2871.4|  2871.5| 8112.0|[2872.71,2872.75,...|\n",
      "|2021-09-03 15:51:00| 2873.81|2874.11|  2872.59| 2872.59| 5406.0|[2873.81,2874.11,...|\n",
      "|2021-09-03 15:50:00| 2874.03|2874.08|  2872.91| 2873.53| 5762.0|[2874.03,2874.08,...|\n",
      "+-------------------+--------+-------+---------+--------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|Independent_Features|\n",
      "+--------------------+\n",
      "|[2874.5,2874.5,28...|\n",
      "|[2875.0,2875.0,28...|\n",
      "|[2874.79,2874.79,...|\n",
      "|[2875.0,2875.0,28...|\n",
      "|[2874.79,2874.79,...|\n",
      "|[2874.5,2874.5,28...|\n",
      "|[2875.0,2875.0,28...|\n",
      "|[2874.79,2874.79,...|\n",
      "|[2874.79,2874.79,...|\n",
      "|[2872.24,2875.16,...|\n",
      "|[2870.745,2872.57...|\n",
      "|[2869.33,2870.83,...|\n",
      "|[2868.44,2870.08,...|\n",
      "|[2869.67,2869.71,...|\n",
      "|[2871.14,2871.62,...|\n",
      "|[2871.2,2872.17,2...|\n",
      "|[2871.625,2872.22...|\n",
      "|[2872.71,2872.75,...|\n",
      "|[2873.81,2874.11,...|\n",
      "|[2874.03,2874.08,...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------------+--------------------+---------+\n",
      "|               date|Independent_Features|    Close|\n",
      "+-------------------+--------------------+---------+\n",
      "|2021-08-23 04:16:00|[2766.91,2766.91,...|  2766.91|\n",
      "|2021-08-23 04:21:00|[2765.0,2765.0,27...|   2765.0|\n",
      "|2021-08-23 04:26:00|[2762.0,2762.0,27...|   2762.0|\n",
      "|2021-08-23 05:23:00|[2764.99,2764.99,...|  2764.99|\n",
      "|2021-08-23 07:15:00|[2760.02,2760.02,...|  2760.02|\n",
      "|2021-08-23 07:23:00|[2758.0,2758.0,27...|   2758.0|\n",
      "|2021-08-23 07:36:00|[2760.02,2761.0,2...|   2761.0|\n",
      "|2021-08-23 07:39:00|[2762.79,2763.09,...|  2763.09|\n",
      "|2021-08-23 07:48:00|[2761.0,2761.0,27...|   2761.0|\n",
      "|2021-08-23 08:01:00|[2755.21,2755.21,...|  2755.21|\n",
      "|2021-08-23 08:23:00|[2758.8,2758.8,27...|   2758.8|\n",
      "|2021-08-23 09:07:00|[2758.8,2759.0,27...|   2759.0|\n",
      "|2021-08-23 09:25:00|[2760.0,2760.0,27...|   2760.0|\n",
      "|2021-08-23 09:26:00|[2760.0,2760.4,27...|   2760.2|\n",
      "|2021-08-23 09:29:00|[2757.85,2757.85,...|  2757.85|\n",
      "|2021-08-23 09:31:00|[2759.39,2761.67,...| 2760.355|\n",
      "|2021-08-23 09:32:00|[2758.59,2761.34,...|2759.1776|\n",
      "|2021-08-23 09:33:00|[2759.77,2760.44,...| 2757.655|\n",
      "|2021-08-23 09:34:00|[2757.91,2760.569...|   2755.0|\n",
      "|2021-08-23 09:35:00|[2754.215,2758.45...|  2752.15|\n",
      "+-------------------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''TRANSFORMATION'''\n",
    "\n",
    "'''vectorizing the columns assembler combine all  features before training or scoring the model'''\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "featureassembler=VectorAssembler(inputCols=[\"Open\",\"High\",\"Low\"],outputCol=\"Independent_Features\")\n",
    "\n",
    "output=featureassembler.transform(stock_price_data)\n",
    "output.show()\n",
    "'''see the vectorized feature'''\n",
    "output.select(\"Independent_Features\").show()\n",
    "output.columns\n",
    "'''get the sorted column'''\n",
    "finalized_data=output.select(\"date\",\"Independent_Features\",\"Close\").sort(\"date\",ascending=True)\n",
    "finalized_data.show()\n",
    "\n",
    "\n",
    "'''Divide the data for Training and Testing'''\n",
    "\n",
    "# finalized_data = finalized_data.toPandas()\n",
    "\n",
    "# # spliting the dataset in ratio 8:2 \n",
    "# # train_data, test_data = finalized_data.split([0.80,0.20])\n",
    "# test_data, train_data = np.split(finalized_data, [int(.2*len(finalized_data))])\n",
    "\n",
    "# test_data.to_parquet(\"test_data.parquet\")\n",
    "# # print(test_data.shape[0], train_data.shape[0])\n",
    "\n",
    "# train_data = spark.createDataFrame(train_data)\n",
    "# test_data = spark.createDataFrame(test_data)\n",
    "# test_data.write.parquet('test_data')\n",
    "# type(test_data)\n",
    "\n",
    "# spliting the dataset in ratio 8:2 \n",
    "final_data = finalized_data.withColumn(\"rank\",percent_rank().over(Window.partitionBy().orderBy(\"date\")))\n",
    "\n",
    "train_data = final_data.where(\"rank <= .8\").drop(\"rank\")\n",
    "test_data = final_data.where(\"rank > .8\").drop(\"rank\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-08 23:39:56,895 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "test_data.write.parquet(\"test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-08 23:47:24,918 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2021-09-08 23:47:26,349 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2021-09-08 23:47:26,713 WARN util.Instrumentation: [ad67ffca] regParam is zero, which might cause numerical instability and overfitting.\n",
      "2021-09-08 23:47:29,362 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "2021-09-08 23:47:29,363 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "2021-09-08 23:47:29,479 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "2021-09-08 23:47:29,480 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "2021-09-08 23:47:29,731 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2021-09-08 23:47:31,430 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2021-09-08 23:47:31,724 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2021-09-08 23:47:34,754 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.27007788492827467,0.3926965969468253,0.33033448832919166]\n",
      "Intercept: 19.694201390375785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-08 23:47:36,346 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------------------+\n",
      "| Close|Independent_Features|        prediction|\n",
      "+------+--------------------+------------------+\n",
      "|2904.0|[2904.0,2904.0,29...|2903.6826508636386|\n",
      "|2904.0|[2904.0,2904.0,29...|2903.6826508636386|\n",
      "|2904.3|[2904.3,2904.3,29...|   2903.9805835547|\n",
      "|2905.5|[2905.5,2905.5,29...| 2905.172314318945|\n",
      "|2904.0|[2904.0,2904.0,29...|2903.6826508636386|\n",
      "+------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-08 23:47:38,433 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.987752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved succesfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''BUILDING MODEL'''\n",
    "'''USe linear regression alogorithm for model fiting'''\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "regressor=LinearRegression(featuresCol='Independent_Features', labelCol='Close')\n",
    "regressor=regressor.fit(train_data)\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'Independent_Features', labelCol='Close', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_data)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))\n",
    "\n",
    "'''TESTING'''\n",
    "'''testing the data get the accuracy by using root mean square '''\n",
    "\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "lr_predictions.select(\"Close\",\"Independent_Features\",\"prediction\").show(5)\n",
    "\n",
    "'''EVALUATION'''\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"Close\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))\n",
    "\n",
    "'''Saving Model'''\n",
    "\n",
    "from pyspark.ml.regression import LinearRegressionModel\n",
    "lr_model.write().overwrite().save(\"stock_Model\")\n",
    "print(\"saved succesfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model and testing on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "mlModel = LinearRegressionModel.load(\"/user/ayur/stock_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-08 23:47:59,358 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+---------+------------------+\n",
      "|               date|Independent_Features|    Close|        prediction|\n",
      "+-------------------+--------------------+---------+------------------+\n",
      "|2021-09-02 08:17:00|[2904.0,2904.0,29...|   2904.0|2903.6826508636386|\n",
      "|2021-09-02 08:43:00|[2904.0,2904.0,29...|   2904.0|2903.6826508636386|\n",
      "|2021-09-02 08:56:00|[2904.3,2904.3,29...|   2904.3|   2903.9805835547|\n",
      "|2021-09-02 09:13:00|[2905.5,2905.5,29...|   2905.5| 2905.172314318945|\n",
      "|2021-09-02 09:14:00|[2904.0,2904.0,29...|   2904.0|2903.6826508636386|\n",
      "|2021-09-02 09:26:00|[2904.0,2904.0,29...|   2904.0|2903.6826508636386|\n",
      "|2021-09-02 09:30:00|[2902.0,2906.33,2...|  2906.33|2903.3968091880097|\n",
      "|2021-09-02 09:31:00|[2904.32,2907.62,...|  2907.62| 2902.412524420915|\n",
      "|2021-09-02 09:32:00|[2908.835,2910.37...|  2910.37| 2908.409110473594|\n",
      "|2021-09-02 09:33:00|[2910.385,2910.38...|  2905.24|2908.3240806959393|\n",
      "|2021-09-02 09:34:00|[2905.055,2906.06...|  2902.49|2904.2796964275562|\n",
      "|2021-09-02 09:35:00|[2902.64,2902.64,...|   2894.8|2899.6265832047443|\n",
      "|2021-09-02 09:36:00|[2895.35,2896.36,...|  2892.63| 2893.662594582111|\n",
      "|2021-09-02 09:37:00|[2893.23,2895.19,...|  2894.78|2893.7565525845544|\n",
      "|2021-09-02 09:38:00|[2893.59,2898.07,...|  2897.14|2894.9120732349033|\n",
      "|2021-09-02 09:39:00|[2895.51,2896.26,...|2895.0567|  2895.09972659507|\n",
      "|2021-09-02 09:40:00|[2894.59,2897.05,...| 2894.045| 2895.123496786366|\n",
      "|2021-09-02 09:41:00|[2895.43,2895.47,...|   2892.9|2894.3516685973927|\n",
      "|2021-09-02 09:42:00|[2892.94,2895.235...|   2892.0| 2893.289589924143|\n",
      "|2021-09-02 09:43:00|[2891.01,2892.27,...| 2891.785| 2891.267053018188|\n",
      "+-------------------+--------------------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "test_op = mlModel.transform(test_data)\n",
    "test_op.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}